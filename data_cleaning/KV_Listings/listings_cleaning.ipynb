{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ca666021",
   "metadata": {},
   "source": [
    "Rental data cleaning and exploration for the listings scraped in Tartu and Tallinn\n",
    "In this notebook we look over the scraped data from kv.ee and discard any unimportant, unhelpful or unneccesary data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1f7a36d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Importing required libraries\n",
    "\n",
    "import pandas as pd\n",
    "import json\n",
    "import numpy as np\n",
    "import os\n",
    "from pathlib import Path\n",
    "\n",
    "#Display settings for better data viewing\n",
    "\n",
    "pd.set_option(\"display.max_columns\", None)\n",
    "pd.set_option(\"display.max_rows\", 100)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "533e3375",
   "metadata": {},
   "source": [
    "Listing all the files in our specific data folder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4fec9d07",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 4 JSON files:\n",
      "  - scraped_listings_tln.json\n",
      "  - scraped_listings_trt.json\n",
      "  - scrape_tln.json\n",
      "  - scrape_trt.json\n"
     ]
    }
   ],
   "source": [
    "data_folder = Path('../../Data_11.04.25')\n",
    "\n",
    "# List all JSON files in the data folder\n",
    "json_files = list(data_folder.glob('*.json'))\n",
    "print(f\"Found {len(json_files)} JSON files:\")\n",
    "for f in json_files:\n",
    "    print(f\"  - {f.name}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fbb7b2bc",
   "metadata": {},
   "source": [
    "Loading  the json files for listings and converting to DataFrame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8db7b986",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading 2 specific JSON files:\n",
      "  ✓ scraped_listings_tln.json\n",
      "  ✓ scraped_listings_trt.json\n",
      "✓ Loaded 1359 records from scraped_listings_tln.json\n",
      "✓ Loaded 450 records from scraped_listings_trt.json\n",
      "\n",
      "Total records loaded: 1809\n",
      "DataFrame shape: (1809, 20)\n",
      "Columns (20): ['id', 'url', 'price', 'latitude', 'longitude', 'Üürida korter', 'Tube', 'Üldpind', 'Korrus/Korruseid', 'Ehitusaasta', 'Seisukord', 'Korruseid', 'Magamistube', 'Energiamärgis', 'Omandivorm', 'Ettemaks', 'Kulud suvel/talvel', 'Katastrinumber', 'Üürida korter (Broneeritud)', 'Registriosa number']\n"
     ]
    }
   ],
   "source": [
    "\n",
    "json_files = [\n",
    "    data_folder / 'scraped_listings_tln.json',\n",
    "    data_folder / 'scraped_listings_trt.json'\n",
    "]\n",
    "\n",
    "print(f\"Loading {len(json_files)} specific JSON files:\")\n",
    "for f in json_files:\n",
    "    exists = \"✓\" if f.exists() else \"✗ NOT FOUND\"\n",
    "    print(f\"  {exists} {f.name}\")\n",
    "\n",
    "# Load all given JSON files\n",
    "all_data = []\n",
    "for file_path in json_files:\n",
    "    try:\n",
    "        with open(file_path, 'r', encoding='utf-8') as f:\n",
    "            data = json.load(f)\n",
    "            all_data.extend(data)\n",
    "            print(f\"✓ Loaded {len(data)} records from {file_path.name}\")\n",
    "    except Exception as e:\n",
    "        print(f\"✗ Error loading {file_path.name}: {e}\")\n",
    "\n",
    "print(f\"\\nTotal records loaded: {len(all_data)}\")\n",
    "\n",
    "# Convert to DataFrame\n",
    "df = pd.DataFrame(all_data)\n",
    "print(f\"DataFrame shape: {df.shape}\")\n",
    "print(f\"Columns ({len(df.columns)}): {df.columns.tolist()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f9534481",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "id                             object\n",
       "url                            object\n",
       "price                          object\n",
       "latitude                       object\n",
       "longitude                      object\n",
       "Üürida korter                  object\n",
       "Tube                           object\n",
       "Üldpind                        object\n",
       "Korrus/Korruseid               object\n",
       "Ehitusaasta                    object\n",
       "Seisukord                      object\n",
       "Korruseid                      object\n",
       "Magamistube                    object\n",
       "Energiamärgis                  object\n",
       "Omandivorm                     object\n",
       "Ettemaks                       object\n",
       "Kulud suvel/talvel             object\n",
       "Katastrinumber                 object\n",
       "Üürida korter (Broneeritud)    object\n",
       "Registriosa number             object\n",
       "dtype: object"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# checking the data types\n",
    "df.head()\n",
    "df.dtypes"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eeac93fd",
   "metadata": {},
   "source": [
    "Missing values analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "9079d62f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Column</th>\n",
       "      <th>Missing_Count</th>\n",
       "      <th>Missing_Pct</th>\n",
       "      <th>Non_Null</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>Üürida korter (Broneeritud)</td>\n",
       "      <td>1717</td>\n",
       "      <td>94.91</td>\n",
       "      <td>92</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>Korruseid</td>\n",
       "      <td>1707</td>\n",
       "      <td>94.36</td>\n",
       "      <td>102</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>Registriosa number</td>\n",
       "      <td>1662</td>\n",
       "      <td>91.87</td>\n",
       "      <td>147</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>Ettemaks</td>\n",
       "      <td>1406</td>\n",
       "      <td>77.72</td>\n",
       "      <td>403</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>Kulud suvel/talvel</td>\n",
       "      <td>1178</td>\n",
       "      <td>65.12</td>\n",
       "      <td>631</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>Katastrinumber</td>\n",
       "      <td>640</td>\n",
       "      <td>35.38</td>\n",
       "      <td>1169</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>Omandivorm</td>\n",
       "      <td>550</td>\n",
       "      <td>30.40</td>\n",
       "      <td>1259</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>Magamistube</td>\n",
       "      <td>513</td>\n",
       "      <td>28.36</td>\n",
       "      <td>1296</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>Energiamärgis</td>\n",
       "      <td>503</td>\n",
       "      <td>27.81</td>\n",
       "      <td>1306</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Ehitusaasta</td>\n",
       "      <td>332</td>\n",
       "      <td>18.35</td>\n",
       "      <td>1477</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Korrus/Korruseid</td>\n",
       "      <td>132</td>\n",
       "      <td>7.30</td>\n",
       "      <td>1677</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Üürida korter</td>\n",
       "      <td>94</td>\n",
       "      <td>5.20</td>\n",
       "      <td>1715</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>Seisukord</td>\n",
       "      <td>63</td>\n",
       "      <td>3.48</td>\n",
       "      <td>1746</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Tube</td>\n",
       "      <td>10</td>\n",
       "      <td>0.55</td>\n",
       "      <td>1799</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Üldpind</td>\n",
       "      <td>3</td>\n",
       "      <td>0.17</td>\n",
       "      <td>1806</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>price</td>\n",
       "      <td>3</td>\n",
       "      <td>0.17</td>\n",
       "      <td>1806</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>latitude</td>\n",
       "      <td>2</td>\n",
       "      <td>0.11</td>\n",
       "      <td>1807</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>longitude</td>\n",
       "      <td>2</td>\n",
       "      <td>0.11</td>\n",
       "      <td>1807</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>id</td>\n",
       "      <td>0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1809</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>url</td>\n",
       "      <td>0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1809</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                         Column  Missing_Count  Missing_Pct  Non_Null\n",
       "18  Üürida korter (Broneeritud)           1717        94.91        92\n",
       "11                    Korruseid           1707        94.36       102\n",
       "19           Registriosa number           1662        91.87       147\n",
       "15                     Ettemaks           1406        77.72       403\n",
       "16           Kulud suvel/talvel           1178        65.12       631\n",
       "17               Katastrinumber            640        35.38      1169\n",
       "14                   Omandivorm            550        30.40      1259\n",
       "12                  Magamistube            513        28.36      1296\n",
       "13                Energiamärgis            503        27.81      1306\n",
       "9                   Ehitusaasta            332        18.35      1477\n",
       "8              Korrus/Korruseid            132         7.30      1677\n",
       "5                 Üürida korter             94         5.20      1715\n",
       "10                    Seisukord             63         3.48      1746\n",
       "6                          Tube             10         0.55      1799\n",
       "7                       Üldpind              3         0.17      1806\n",
       "2                         price              3         0.17      1806\n",
       "3                      latitude              2         0.11      1807\n",
       "4                     longitude              2         0.11      1807\n",
       "0                            id              0         0.00      1809\n",
       "1                           url              0         0.00      1809"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "missing_stats = pd.DataFrame({\n",
    "    'Column': df.columns,\n",
    "    'Missing_Count': df.isnull().sum().values,\n",
    "    'Missing_Pct': (df.isnull().sum().values / len(df) * 100).round(2),\n",
    "    'Non_Null': df.notnull().sum().values\n",
    "}).sort_values('Missing_Pct', ascending=False)\n",
    "\n",
    "missing_stats"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "41806160",
   "metadata": {},
   "source": [
    "Taking a look at columns with high missing rates (over 20%)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "4da9398c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Columns with >20% missing: 9\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Column</th>\n",
       "      <th>Missing_Count</th>\n",
       "      <th>Missing_Pct</th>\n",
       "      <th>Non_Null</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>Üürida korter (Broneeritud)</td>\n",
       "      <td>1717</td>\n",
       "      <td>94.91</td>\n",
       "      <td>92</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>Korruseid</td>\n",
       "      <td>1707</td>\n",
       "      <td>94.36</td>\n",
       "      <td>102</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>Registriosa number</td>\n",
       "      <td>1662</td>\n",
       "      <td>91.87</td>\n",
       "      <td>147</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>Ettemaks</td>\n",
       "      <td>1406</td>\n",
       "      <td>77.72</td>\n",
       "      <td>403</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>Kulud suvel/talvel</td>\n",
       "      <td>1178</td>\n",
       "      <td>65.12</td>\n",
       "      <td>631</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>Katastrinumber</td>\n",
       "      <td>640</td>\n",
       "      <td>35.38</td>\n",
       "      <td>1169</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>Omandivorm</td>\n",
       "      <td>550</td>\n",
       "      <td>30.40</td>\n",
       "      <td>1259</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>Magamistube</td>\n",
       "      <td>513</td>\n",
       "      <td>28.36</td>\n",
       "      <td>1296</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>Energiamärgis</td>\n",
       "      <td>503</td>\n",
       "      <td>27.81</td>\n",
       "      <td>1306</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                         Column  Missing_Count  Missing_Pct  Non_Null\n",
       "18  Üürida korter (Broneeritud)           1717        94.91        92\n",
       "11                    Korruseid           1707        94.36       102\n",
       "19           Registriosa number           1662        91.87       147\n",
       "15                     Ettemaks           1406        77.72       403\n",
       "16           Kulud suvel/talvel           1178        65.12       631\n",
       "17               Katastrinumber            640        35.38      1169\n",
       "14                   Omandivorm            550        30.40      1259\n",
       "12                  Magamistube            513        28.36      1296\n",
       "13                Energiamärgis            503        27.81      1306"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "high_missing = missing_stats[missing_stats['Missing_Pct'] > 20]\n",
    "print(f\"Columns with >20% missing: {len(high_missing)}\")\n",
    "high_missing\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "98fa39a9",
   "metadata": {},
   "source": [
    "Taking sample values from key columns and checking for duplicate ID's. For better understanding of the format of the data gotten."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "099b39ad",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "price: 1571 unique | Sample:\n",
      "['595\\xa0€  8.75 €/m²', '365\\xa0€  9.13 €/m²', '1\\xa0100\\xa0€  9.96 €/m²', '220\\xa0€  14.7 €/m²', '850\\xa0€  11.3 €/m²']\n",
      "\n",
      "Tube: 6 unique | Sample:\n",
      "['3', '1', '3', '1', '3']\n",
      "\n",
      "Üldpind: 695 unique | Sample:\n",
      "['68\\xa0m²', '40\\xa0m²', '110.4\\xa0m²', '15\\xa0m²', '75\\xa0m²']\n",
      "\n",
      "Korrus/Korruseid: 108 unique | Sample:\n",
      "['6/9', '3/3', '2/3', '2/4', '2/5']\n",
      "\n",
      "Ehitusaasta: 127 unique | Sample:\n",
      "['1990', '1911', '1933', '2015', '2007']\n",
      "\n",
      "Seisukord: 8 unique | Sample:\n",
      "['San. remont tehtud', 'Renoveeritud', 'San. remont tehtud', 'Renoveeritud', 'Heas korras']\n",
      "Duplicate IDs: 0\n"
     ]
    }
   ],
   "source": [
    "key_cols = ['price', 'Tube', 'Üldpind', 'Korrus/Korruseid', 'Ehitusaasta', 'Seisukord']\n",
    "for col in key_cols:\n",
    "    if col in df.columns:\n",
    "        print(f\"\\n{col}: {df[col].nunique()} unique | Sample:\")\n",
    "        print(df[col].dropna().head(5).tolist())\n",
    "\n",
    "# Check for duplicate IDs\n",
    "dups = df.duplicated(subset=['id']).sum()\n",
    "print(f\"Duplicate IDs: {dups}\")\n",
    "if dups > 0:\n",
    "    df[df.duplicated(subset=['id'], keep=False)].sort_values('id')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef5859f9",
   "metadata": {},
   "source": [
    "Making a clean copy of the dataset before cleaning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "72b06055",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✓ Original data backed up\n"
     ]
    }
   ],
   "source": [
    "df_original = df.copy(deep=True)\n",
    "print(\"✓ Original data backed up\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "defb9709",
   "metadata": {},
   "source": [
    "Data cleaning - counting the missing values and stripping whitespace"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "5b4595dd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "id: no missing values\n",
      "url: no missing values\n",
      "price: 0.17%\n",
      "latitude: 0.11%\n",
      "longitude: 0.11%\n",
      "Üürida korter: 5.2%\n",
      "Tube: 0.55%\n",
      "Üldpind: 0.17%\n",
      "Korrus/Korruseid: 7.3%\n",
      "Ehitusaasta: 18.35%\n",
      "Seisukord: 3.48%\n",
      "Korruseid: 94.36%\n",
      "Magamistube: 28.36%\n",
      "Energiamärgis: 27.81%\n",
      "Omandivorm: 30.4%\n",
      "Ettemaks: 77.72%\n",
      "Kulud suvel/talvel: 65.12%\n",
      "Katastrinumber: 35.38%\n",
      "Üürida korter (Broneeritud): 94.91%\n",
      "Registriosa number: 91.87%\n"
     ]
    }
   ],
   "source": [
    "total_rows = len(df)\n",
    "for column in df.columns:\n",
    "    # Count \"?\" and NaN as missing\n",
    "    total_missing = (df[column].astype(str).str.strip() == \"?\").sum() + df[column].isna().sum()\n",
    "    if total_missing > 0:\n",
    "        missing_pct = (total_missing/total_rows)*100\n",
    "        print(f\"{column}: {missing_pct.round(2)}%\")\n",
    "    else:\n",
    "        print(f\"{column}: no missing values\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee1b1880",
   "metadata": {},
   "source": [
    "Stripping whitespace from string columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "069d6874",
   "metadata": {},
   "outputs": [],
   "source": [
    "for column in df.columns:\n",
    "    if df[column].dtype == 'object':\n",
    "        stripped_series = df[column].str.strip()\n",
    "        if not df[column].equals(stripped_series):\n",
    "            df[column] = stripped_series\n",
    "            print(f\"✓ Stripped whitespace from {column}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "767536d3",
   "metadata": {},
   "source": [
    "Replacing \"?\" with np.nan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "7fce3f47",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cleaning text data...\n",
      "✓ Replaced '?' with NaN and cleaned non-breaking spaces\n"
     ]
    }
   ],
   "source": [
    "print(\"Cleaning text data...\")\n",
    "for column in df.columns:\n",
    "    if df[column].dtype == 'object':\n",
    "        # Replace various forms of \"?\"\n",
    "        df[column] = df[column].replace('?', np.nan)\n",
    "        df[column] = df[column].replace(' ?', np.nan)\n",
    "        df[column] = df[column].replace('? ', np.nan)\n",
    "        # Replace non-breaking spaces (\\xa0) with regular spaces\n",
    "        df[column] = df[column].str.replace('\\xa0', ' ', regex=False)\n",
    "\n",
    "print(\"✓ Replaced '?' with NaN and cleaned non-breaking spaces\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "29a35bb8",
   "metadata": {},
   "source": [
    "Data cleaning - Extract numeric price from format 450 € / 6.79€/meters squared"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "5ded8105",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Price extraction: 1805 / 1809 successful\n",
      "Price range: 1 - 7500 €\n",
      "Data type: float64\n"
     ]
    }
   ],
   "source": [
    "def extract_price(price_str):\n",
    "    \"\"\"Extract monthly rent from '450 € 6.79 €/m²' format\"\"\"\n",
    "    if pd.isna(price_str):\n",
    "        return np.nan\n",
    "    try:\n",
    "        # Remove all spaces and take first number before €\n",
    "        clean_str = str(price_str).replace(' ', '').split('€')[0]\n",
    "        return float(clean_str)\n",
    "    except:\n",
    "        return np.nan\n",
    "\n",
    "df['price_clean'] = df['price'].apply(extract_price)\n",
    "print(f\"Price extraction: {df['price_clean'].notna().sum()} / {len(df)} successful\")\n",
    "print(f\"Price range: {df['price_clean'].min():.0f} - {df['price_clean'].max():.0f} €\")\n",
    "print(f\"Data type: {df['price_clean'].dtype}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b09031c",
   "metadata": {},
   "source": [
    "Extracting square meters from same format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "759d2c6f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Area extraction: 1806 / 1809 successful\n",
      "Area range: 7.0 - 264.0 m²\n"
     ]
    }
   ],
   "source": [
    "def extract_sqm(area_str):\n",
    "    \"\"\"Extract numeric area from '66.3 m²' format\"\"\"\n",
    "    if pd.isna(area_str):\n",
    "        return np.nan\n",
    "    try:\n",
    "        # Remove spaces and 'm²', then convert to float\n",
    "        clean_str = str(area_str).replace(' ', '').replace('m²', '')\n",
    "        return float(clean_str)\n",
    "    except:\n",
    "        return np.nan\n",
    "\n",
    "df['area_sqm'] = df['Üldpind'].apply(extract_sqm)\n",
    "print(f\"Area extraction: {df['area_sqm'].notna().sum()} / {len(df)} successful\")\n",
    "print(f\"Area range: {df['area_sqm'].min():.1f} - {df['area_sqm'].max():.1f} m²\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed898feb",
   "metadata": {},
   "source": [
    "Split floor information - make \"on which floor\" and \"how many floors on this house\" separate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "bbb41d11",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Floor extraction: 1677 / 1809 successful\n"
     ]
    }
   ],
   "source": [
    "def extract_floor(floor_str):\n",
    "    \"\"\"Extract floor and total floors from '3/9' format\"\"\"\n",
    "    if pd.isna(floor_str):\n",
    "        return np.nan, np.nan\n",
    "    try:\n",
    "        parts = floor_str.split('/')\n",
    "        floor = int(parts[0].strip())\n",
    "        total = int(parts[1].strip())\n",
    "        return floor, total\n",
    "    except:\n",
    "        return np.nan, np.nan\n",
    "\n",
    "df[['floor', 'total_floors']] = df['Korrus/Korruseid'].apply(\n",
    "    lambda x: pd.Series(extract_floor(x))\n",
    ")\n",
    "print(f\"Floor extraction: {df['floor'].notna().sum()} / {len(df)} successful\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b4c81be",
   "metadata": {},
   "source": [
    "Converting room numbers to numeric"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "5a052277",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rooms: 1799 / 1809 valid\n",
      "Unique room values: [np.float64(1.0), np.float64(2.0), np.float64(3.0), np.float64(4.0), np.float64(5.0), np.float64(6.0)]\n"
     ]
    }
   ],
   "source": [
    "df['rooms'] = pd.to_numeric(df['Tube'], errors='coerce')\n",
    "print(f\"Rooms: {df['rooms'].notna().sum()} / {len(df)} valid\")\n",
    "print(f\"Unique room values: {sorted(df['rooms'].dropna().unique())}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "772f347f",
   "metadata": {},
   "source": [
    "Clean construction year (change to numeric and check for outliers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "2c61047a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Build year: 1469 / 1809 valid\n",
      "Year range: 1807 - 2025\n",
      "Removed 8 suspicious years\n",
      "Data type: float64\n"
     ]
    }
   ],
   "source": [
    "df['build_year'] = pd.to_numeric(df['Ehitusaasta'], errors='coerce')\n",
    "\n",
    "# Validate build year - (e.g. there is an outlier with build year 1377)\n",
    "# We assumed a  valid range is 1800-2025\n",
    "df.loc[df['build_year'] < 1800, 'build_year'] = np.nan\n",
    "df.loc[df['build_year'] > 2025, 'build_year'] = np.nan\n",
    "\n",
    "print(f\"Build year: {df['build_year'].notna().sum()} / {len(df)} valid\")\n",
    "if df['build_year'].notna().sum() > 0:\n",
    "    print(f\"Year range: {df['build_year'].min():.0f} - {df['build_year'].max():.0f}\")\n",
    "print(f\"Removed {(pd.to_numeric(df['Ehitusaasta'], errors='coerce').notna() & df['build_year'].isna()).sum()} suspicious years\")\n",
    "print(f\"Data type: {df['build_year'].dtype}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b6b6d87c",
   "metadata": {},
   "source": [
    "Extracting deposit amounts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "721bd208",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_deposit(deposit_str):\n",
    "    \"\"\"Extract deposit from '900 €' format\"\"\"\n",
    "    if pd.isna(deposit_str):\n",
    "        return np.nan\n",
    "    try:\n",
    "        return float(deposit_str.replace('€', '').strip())\n",
    "    except:\n",
    "        return np.nan\n",
    "\n",
    "df['deposit'] = df['Ettemaks'].apply(extract_deposit)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b1bffa7",
   "metadata": {},
   "source": [
    "Validating coordinates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "fb72415f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Valid coordinates: 1807 / 1809\n"
     ]
    }
   ],
   "source": [
    "df['latitude'] = pd.to_numeric(df['latitude'], errors='coerce')\n",
    "df['longitude'] = pd.to_numeric(df['longitude'], errors='coerce')\n",
    "\n",
    "# Estonia roughly: lat 57.5-59.7, lon 21.5-28.2\n",
    "valid_coords = (\n",
    "    (df['latitude'] >= 57) & (df['latitude'] <= 60) &\n",
    "    (df['longitude'] >= 21) & (df['longitude'] <= 29)\n",
    ")\n",
    "print(f\"Valid coordinates: {valid_coords.sum()} / {len(df)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ecadf667",
   "metadata": {},
   "source": [
    "Selecting the columns to be kept - (everything with missing rate over 20% will be removed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "5eb334c3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating ALL columns based on missing data threshold (>20%):\n",
      "============================================================\n",
      "✓ id                                  (  0.00% missing)\n",
      "✓ url                                 (  0.00% missing)\n",
      "✓ price                               (  0.17% missing)\n",
      "✓ latitude                            (  0.11% missing)\n",
      "✓ longitude                           (  0.11% missing)\n",
      "✓ Üürida korter                       (  5.20% missing)\n",
      "✓ Tube                                (  0.55% missing)\n",
      "✓ Üldpind                             (  0.17% missing)\n",
      "✓ Korrus/Korruseid                    (  7.30% missing)\n",
      "✓ Ehitusaasta                         ( 18.35% missing)\n",
      "✓ Seisukord                           (  3.48% missing)\n",
      "✗ Korruseid                           ( 94.36% missing) - REMOVED\n",
      "✗ Magamistube                         ( 28.36% missing) - REMOVED\n",
      "✗ Energiamärgis                       ( 27.81% missing) - REMOVED\n",
      "✗ Omandivorm                          ( 30.40% missing) - REMOVED\n",
      "✗ Ettemaks                            ( 77.72% missing) - REMOVED\n",
      "✗ Kulud suvel/talvel                  ( 65.12% missing) - REMOVED\n",
      "✗ Katastrinumber                      ( 35.38% missing) - REMOVED\n",
      "✗ Üürida korter (Broneeritud)         ( 94.91% missing) - REMOVED\n",
      "✗ Registriosa number                  ( 91.87% missing) - REMOVED\n",
      "✓ price_clean                         (  0.22% missing)\n",
      "✓ area_sqm                            (  0.17% missing)\n",
      "✓ floor                               (  7.30% missing)\n",
      "✓ total_floors                        (  7.30% missing)\n",
      "✓ rooms                               (  0.55% missing)\n",
      "✓ build_year                          ( 18.79% missing)\n",
      "✗ deposit                             ( 81.15% missing) - REMOVED\n",
      "\n",
      "============================================================\n",
      "Kept 17 columns, removed 10 columns\n",
      "\n",
      "Removed columns: ['Korruseid', 'Magamistube', 'Energiamärgis', 'Omandivorm', 'Ettemaks', 'Kulud suvel/talvel', 'Katastrinumber', 'Üürida korter (Broneeritud)', 'Registriosa number', 'deposit']\n",
      "============================================================\n"
     ]
    }
   ],
   "source": [
    "missing_threshold = 20  # Remove columns with >20% missing data\n",
    "\n",
    "print(\"Evaluating ALL columns based on missing data threshold (>20%):\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "# Check all columns in the original dataframe\n",
    "columns_to_keep = []\n",
    "removed_columns = []\n",
    "\n",
    "for col in df.columns:\n",
    "    missing_pct = (df[col].isna().sum() / len(df)) * 100\n",
    "    \n",
    "    if missing_pct <= missing_threshold:\n",
    "        columns_to_keep.append(col)\n",
    "        print(f\"✓ {col:35s} ({missing_pct:6.2f}% missing)\")\n",
    "    else:\n",
    "        removed_columns.append(col)\n",
    "        print(f\"✗ {col:35s} ({missing_pct:6.2f}% missing) - REMOVED\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(f\"Kept {len(columns_to_keep)} columns, removed {len(removed_columns)} columns\")\n",
    "print(f\"\\nRemoved columns: {removed_columns}\")\n",
    "print(\"=\"*60)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "42f52808",
   "metadata": {},
   "source": [
    "Creating the cleaned DataFrame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "76a8a629",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Filtered dataset shape: (1809, 17)\n",
      "Columns remaining: ['id', 'url', 'price', 'latitude', 'longitude', 'Üürida korter', 'Tube', 'Üldpind', 'Korrus/Korruseid', 'Ehitusaasta', 'Seisukord', 'price_clean', 'area_sqm', 'floor', 'total_floors', 'rooms', 'build_year']\n",
      "\n",
      "Final cleaned dataset with 11 columns:\n",
      "Columns: ['id', 'url', 'latitude', 'longitude', 'condition', 'price', 'area_sqm', 'floor', 'total_floors', 'rooms', 'build_year']\n"
     ]
    }
   ],
   "source": [
    "df_filtered = df[columns_to_keep].copy()\n",
    "\n",
    "print(f\"\\nFiltered dataset shape: {df_filtered.shape}\")\n",
    "print(f\"Columns remaining: {df_filtered.columns.tolist()}\")\n",
    "\n",
    "# Map original columns to clean English names for the columns we kept\n",
    "column_mapping = {\n",
    "    'id': 'id',\n",
    "    'url': 'url',\n",
    "    'price': 'price_raw',\n",
    "    'latitude': 'latitude',\n",
    "    'longitude': 'longitude',\n",
    "    'Üürida korter': 'rental_ad',\n",
    "    'Tube': 'rooms_raw',\n",
    "    'Üldpind': 'area_raw',\n",
    "    'Korrus/Korruseid': 'floor_raw',\n",
    "    'Ehitusaasta': 'build_year_raw',\n",
    "    'Seisukord': 'condition',\n",
    "    'Korruseid': 'total_floors_alt',\n",
    "    'Magamistube': 'bedrooms',\n",
    "    'Energiamärgis': 'energy_label',\n",
    "    'Omandivorm': 'ownership_type',\n",
    "    # Cleaned columns\n",
    "    'price_clean': 'price',\n",
    "    'area_sqm': 'area_sqm',\n",
    "    'rooms': 'rooms',\n",
    "    'floor': 'floor',\n",
    "    'total_floors': 'total_floors',\n",
    "    'build_year': 'build_year'\n",
    "}\n",
    "\n",
    "# Selecting only the cleaned numeric columns we created + essential info\n",
    "final_columns = []\n",
    "final_names = []\n",
    "\n",
    "for col in df_filtered.columns:\n",
    "    if col in ['id', 'url', 'latitude', 'longitude', 'Seisukord', \n",
    "               'price_clean', 'area_sqm', 'rooms', 'floor', 'total_floors', 'build_year']:\n",
    "        final_columns.append(col)\n",
    "        final_names.append(column_mapping.get(col, col))\n",
    "\n",
    "df_clean = df_filtered[final_columns].copy()\n",
    "df_clean.columns = final_names\n",
    "\n",
    "print(f\"\\nFinal cleaned dataset with {len(df_clean.columns)} columns:\")\n",
    "print(f\"Columns: {df_clean.columns.tolist()}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4730fcc2",
   "metadata": {},
   "source": [
    "Checking cleaned data quality"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "e55664b7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cleaned dataset summary:\n",
      "Total rows: 1809\n",
      "\n",
      "Missing values:\n",
      "id                0\n",
      "url               0\n",
      "latitude          2\n",
      "longitude         2\n",
      "condition        63\n",
      "price             4\n",
      "area_sqm          3\n",
      "floor           132\n",
      "total_floors    132\n",
      "rooms            10\n",
      "build_year      340\n",
      "dtype: int64\n",
      "\n",
      "Key statistics:\n",
      "             price     area_sqm        rooms        floor   build_year\n",
      "count  1805.000000  1806.000000  1799.000000  1677.000000  1469.000000\n",
      "mean    712.840443    51.629623     2.121178     3.231962  1986.581348\n",
      "std     506.231734    28.643769     0.921135     2.374131    34.777646\n",
      "min       1.000000     7.000000     1.000000    -1.000000  1807.000000\n",
      "25%     444.000000    33.000000     1.000000     2.000000  1963.000000\n",
      "50%     590.000000    46.900000     2.000000     3.000000  1995.000000\n",
      "75%     800.000000    63.775000     3.000000     4.000000  2018.000000\n",
      "max    7500.000000   264.000000     6.000000    30.000000  2025.000000\n",
      "\n",
      "============================================================\n",
      "DATA QUALITY CHECKS:\n",
      "============================================================\n",
      "\n",
      "Floor values < 0 (basements): 2\n",
      "  → Keeping basement floors as valid data\n",
      "\n",
      "Price distribution:\n",
      "  < 50€: 4 listings → Will be removed (likely errors)\n",
      "  50-100€: 3 listings\n",
      "  100-500€: 647 listings\n",
      "  500-1000€: 889 listings\n",
      "  > 1000€: 262 listings\n",
      "\n",
      "Area distribution:\n",
      "  < 15 m²: 70 listings\n",
      "  15-50 m²: 955 listings\n",
      "  50-100 m²: 664 listings\n",
      "  > 100 m²: 117 listings\n"
     ]
    }
   ],
   "source": [
    "print(\"Cleaned dataset summary:\")\n",
    "print(f\"Total rows: {len(df_clean)}\")\n",
    "print(f\"\\nMissing values:\")\n",
    "print(df_clean.isnull().sum())\n",
    "print(f\"\\nKey statistics:\")\n",
    "print(df_clean[['price', 'area_sqm', 'rooms', 'floor', 'build_year']].describe())\n",
    "\n",
    "# Checking for unusual values\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"DATA QUALITY CHECKS:\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "# Checking floor values (keeping basement floors as they are valid)\n",
    "print(f\"\\nFloor values < 0 (basements): {(df_clean['floor'] < 0).sum()}\")\n",
    "print(\"  → Keeping basement floors as valid data\")\n",
    "\n",
    "# Price range info\n",
    "print(f\"\\nPrice distribution:\")\n",
    "print(f\"  < 50€: {(df_clean['price'] < 50).sum()} listings → Will be removed (likely errors)\")\n",
    "print(f\"  50-100€: {((df_clean['price'] >= 50) & (df_clean['price'] < 100)).sum()} listings\")\n",
    "print(f\"  100-500€: {((df_clean['price'] >= 100) & (df_clean['price'] < 500)).sum()} listings\")\n",
    "print(f\"  500-1000€: {((df_clean['price'] >= 500) & (df_clean['price'] < 1000)).sum()} listings\")\n",
    "print(f\"  > 1000€: {(df_clean['price'] >= 1000).sum()} listings\")\n",
    "\n",
    "# Checking extreme areas\n",
    "print(f\"\\nArea distribution:\")\n",
    "print(f\"  < 15 m²: {(df_clean['area_sqm'] < 15).sum()} listings\")\n",
    "print(f\"  15-50 m²: {((df_clean['area_sqm'] >= 15) & (df_clean['area_sqm'] < 50)).sum()} listings\")\n",
    "print(f\"  50-100 m²: {((df_clean['area_sqm'] >= 50) & (df_clean['area_sqm'] < 100)).sum()} listings\")\n",
    "print(f\"  > 100 m²: {(df_clean['area_sqm'] >= 100).sum()} listings\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c1554b2f",
   "metadata": {},
   "source": [
    "Removing outliers - Properties where price, area_sqm or rooms aren't specified or if they seem...odd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "59287681",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rows after removing records missing critical fields: 1797 (removed 12)\n",
      "Rows after removing prices < 50€: 1793 (removed 4)\n",
      "\n",
      "Final dataset size: 1793 rows\n"
     ]
    }
   ],
   "source": [
    "critical_fields = ['price', 'area_sqm', 'rooms']\n",
    "df_final = df_clean.dropna(subset=critical_fields)\n",
    "print(f\"Rows after removing records missing critical fields: {len(df_final)} (removed {len(df_clean) - len(df_final)})\")\n",
    "\n",
    "# Remove unrealistic prices (< 50€) - likely data errors or non-rental listings\n",
    "before_price_filter = len(df_final)\n",
    "df_final = df_final[df_final['price'] >= 50]\n",
    "print(f\"Rows after removing prices < 50€: {len(df_final)} (removed {before_price_filter - len(df_final)})\")\n",
    "\n",
    "print(f\"\\nFinal dataset size: {len(df_final)} rows\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "65c2e112",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✓ Cleaned data saved to: ..\\..\\Cleaned_csvs\\listings_cleaned.csv\n",
      "Final dataset: (1793, 11)\n"
     ]
    }
   ],
   "source": [
    "output_path = Path('../../Cleaned_csvs/listings_cleaned.csv')\n",
    "df_final.to_csv(output_path, index=False, encoding='utf-8')\n",
    "print(f\"✓ Cleaned data saved to: {output_path}\")\n",
    "print(f\"Final dataset: {df_final.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd67a090",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
